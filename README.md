# Pegasus_Tutorial_Summarization_Test

When time come to summarize infoirmation this activity requied time and cncentratino. using macihine learning to help and perform this task can be an assess.

Output Sapmle:
Natural Language Processing and How Natural Language Processing is Changing the Face of Data Analytics have been used in Data Science in recent years.

Input text
https://analyticsindiamag.com/how-to-paraphrase-text-using-pegasus-transformer/ 

In recent years, if you have explored Data Science, you must have heard or come across the term “Natural Language Processing” and “How Natural Language Processing is changing the face of Data Analytics”. But, what exactly is Natural Language Processing? Natural language refers to the way humans communicate and connect. Today, we are surrounded by text and voice, and text is the two most essential ways of communicating with each other and the society around us. Hence a lot of unstructured data in the form of Voice and Text is generated daily. Noticing the sheer importance of such data types, we must have methods to understand and reason about the natural language present in it, just like we have for other types of data. Natural language processing or NLP refers to the branch of computer science and artificial intelligence, both of which can give computers the ability to understand the text and spoken words the same way human beings can. 
NLP combines the power of computational linguistics with rule-based modeling of human language, wrapped further with statistical, machine learning, and deep learning models. These technologies combined enable computers to process human language in the form of text or voice data and ‘understand’ the meaning behind it or the writer’s intent and sentiment. NLP can also be broadly defined as the automatic manipulation of natural language by software or an algorithm. Machine learning practitioners and Data Scientists are getting interested in working with text data more and more and trying to uncover the tools and methods for working in Natural Language Processing. Data generated from conversations, forms or tweets are potential examples of unstructured data. Unstructured data is the kind of data that doesn’t fit neatly into any traditional row and column structure of the relational databases. It fairly represents the vast majority of data that is available in the actual world. It is messy and hard to manipulate. But thanks to the advances in disciplines like machine learning, there has been a big revolution.
Natural language processing helps computers communicate with humans in their language and bring aid to language-related tasks. NLP makes it possible for computers to read text, hear speech, interpret it, measure sentiment and determine which parts are important and whatnot. Today’s machines are becoming more intelligent with time and can analyze more language-based data than humans and in an unbiased way. Considering the vast amount of unstructured data generated every day, from medical records to social media, automation has been a critical aspect of fully analyzing text and speech data efficiently. NLP algorithms are typically based on machine learning algorithms. Instead of hand-coding large sets of rules, NLP relies on machine learning to automatically learn these rules by analyzing a large corpus, collecting sentences, and making statistical inferences from it. In general, the more data analyzed and trained upon, the more accurate the model will be.
Pegasus Transformer for NLP
Transfer learning and pretrained language models in Natural Language Processing have pushed forward language understanding and generation limits. Transfer learning and applying transformers to different NLP tasks have become a main trend of the latest research advancements. Transformer encoder-decoder models have recently become favoured as they seem more effective at modeling the dependencies present in the long sequences encountered during the summarization process. The PEGASUS model’s pre-training task is very similar to summarization, i.e. important sentences are removed and masked from an input document and are later generated together as one output sequence from the remaining sentences, which is fairly similar to a summary. In PEGASUS, several whole sentences are removed from documents during pre-training, and the model is tasked with recovering them. The Input for such pre-training is a document with missing sentences, while the output consists of the missing sentences being concatenated together. The advantage of this self-supervision is that you can create as many examples as there are documents without any human intervention, which often becomes a bottleneck problem in purely supervised systems.


